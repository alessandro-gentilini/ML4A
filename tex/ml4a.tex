% This file is part of the ML4A project.
% Copyright 2017, 2018 the author.

% style notes:
% ------------
% - Am I consistent about the plurality of ``data''?

\documentclass[12pt, letterpaper]{article}
\usepackage{xcolor}

% typesetting issues
\linespread{1.08333} % 10/13 spacing
\setlength{\topmargin}{-0.25in}
\setlength{\textheight}{9.25in}
\setlength{\headheight}{0.00in}
\setlength{\headsep}{0.00in}
\setlength{\parindent}{1.10\baselineskip}

% text macros
\newcommand{\documentname}{\textsl{Note}}
\newcommand{\foreign}[1]{\textsl{#1}}
\newcommand{\vs}{\foreign{vs}}
\newcommand{\todo}[1]{\textcolor{red}{#1}}  % gotta have \usepackage{xcolor} in main doc or this won't work

\begin{document}\sloppy\sloppypar\raggedbottom\frenchspacing

\section*{Machine learning for astronomers%
\footnote{This \documentname\ is copyright 2017, 2018 the author. Feel free to copy and
distribute it, provided that you make no changes to it whatsoever.}}

\noindent
\textbf{David W. Hogg%
\footnote{For many of the ideas in this \documentname, I am indebted to
  Jo Bovy (Toronto),
  Rob Fergus (NYU),
  Dan Foreman-Mackey (Flatiron),
  Jennifer Hill (NYU),
  Iain Murray (Edinburgh),
  Sam Roweis (deceased),
  and
  Bernhard Sch\"olkopf (MPI-IS).}}\\
\textsl{\footnotesize
  Center for Cosmology and Particle Physics, Department of Physics, New York University \\
  Center for Data Science, New York University \\
  Max-Planck-Institut f\"ur Astronomie, Heidelberg \\
  Flatiron Institute, a division of the Simons Foundation}

\paragraph{Abstract:}
Machine learning---which is hard to define uncontroversially
but which involves expertise-eschewing, data-driven methods for classification,
regression, dimensionality reduction, density estimation, and clustering,
with methods that have great flexibility or even non-parametric form---has transformed all
of the sciences and commerce.
Naturally, it is appearing in many contexts in astronomy and astrophysics and
in such numbers that any kind of review or analysis would now be a fool's errand.
Here I give a very personal discussion of machine-learning methods and lay out the costs and
benefits of their adoption.
And I provide some unsolicited advice!
I highlight the five simplest and most elegant methods I know: support vector
machines, linear regression, principal components analyis, Gaussian mixture models
with expectation maximization, and k-means.
I then discuss their limitations, generalizations, and alternatives, with a focus
on some key qualities:
For most astronomical contexts, we want methods that are interpretable (at least
partially), generalizable (in at least some respects), probabilistic (in that
there is something akin to a likelihood function involved, such that the method can
be inserted into some bigger inference with informed causal structure).
Very few high-performance or computationally tractable methods have any of these
properties, and therefore (in my view),
\emph{most machine-learning methods are not advisable for most astronomical
applications!}
Of course there are exceptions, which I discuss.
Additionally, I spend some time on the magic of kernels and non-parametrics, and in particular
I highlight the Gaussian process, which shows great promise for astronomy.
One of the primary goals of this \documentname\ is to attempt to set down in writing
some of the folk or tacit knowledge that is available in the community, but
(nearly) invisible in the literature.

\clearpage\section{Why machine learning in astronomy?}

Astronomy---thanks to enormous support from public and private funding
agencies---is awash in beautiful and informative data, about planets, stars,
black holes, accretion flows,
the interstellar medium, the Milky Way, the local Universe, and the entire
Hubble Volume, including the surface of last scattering.
For all of these observed phenomena, we have physical models, executed
with large computational simulations, of varying degress of maturity,
that explain the observations.
But of course the data are so rich and so informative and so featured
that no physical model (yet) does justice to all of the details of these
data.
That is, there is far more to see and learn from the data than we can
capture with our (necessarily simplified and limited) physical models.
In some cases, there isn't even a working physical model at all.

It is tempting, therefore, to attempt to transform some of the important
scientific questions in astronomy from questions about how physical models are
constrained by data into a more data-driven form.
That is, when the data are far more featured than any model, it is interesting
to ask whether the data can somehow \emph{become} the model.
And indeed, sometimes questions \emph{can} be so transformed.
For example, when we are looking for tiny, periodic exoplanet transit
signals in the noisy light curve of a variable star, we don't necessarily
need an accurate physical model of the stellar variability:
We can use the empirical properties of the variability learned from
other, similar stars.
When we want to distinguish stars from quasars in multi-band imaging, we
don't necessarily need accurate physical models for stars and quasars,
we can use known stars and quasars to teach us the differences.
In cases like these, the data \emph{is} the model.\footnote{\todo{Something about this phrase.}}

Without digressing into a long discussion of precision and accuracy, I
think it is worth noting here that data-driven methods can achieve
unparalleled accuracy for some tasks:
After all, the observed data provide---or can provide---a very
\emph{accurate} model or picture of astrophysical phenomena \emph{in
  the space of the data}.
That is, if the goal is a model that reproduces the data (as it is in
the planet-finding and classification tasks I just mentioned), a
data-driven model is almost guaranteed to beat any physics-based
model.\footnote{\todo{Argument about modeling the residuals, which is
    more-or-less a proof.}}

And there are other equally important tasks for which data-driven
models can achieve unparalleled \emph{precision}:
If a model is given the flexibility to capture informative features
in a data set that are not captured by other, cruder models, then that
model can use those features for inference.
That is, a sufficiently flexible data-driven model can discover information
sources in the data that more inflexible models might not capture.
This has been true, for example, in our data-driven models of stars\footnote{\todo{cite Ness etc}},
where small issues with atomic, molecular, and plasma physics prevent
physical models of stellar photospheres from achieving the full precision
on (say) element abundances available in the data, but a data-driven
model does better (at least in terms of precision).

Here we are going to look at the space of data-driven models that are
referred to as ``machine learning''.
These are generally and currently the most flexible forms of data-driven
models, and they show great promise for some tasks in astronomy.

If I try to intuit the origins of the name ``machine learning'',
I would guess it relates back to a branch of artificial intelligence,
in which it became interesting to know whether a machine (that,
presumably, does not have the experience or assumptions of a human)
can perform scientific tasks that involve generalizing or learning from
data. \todo{Put a footnote here with a corrective to this.}
Indeed, some of my best friends still use the term
this way, counting any computational inference (any use of a machine
to learn parameters or properties of a data set) as machine learning.
Here I am going to use the term more narrowly, to refer to the computational
inferences that are very scientifically agnostic, that make use of extremely
flexible (highly parameterized or even non-parametric) models, and
that are defined with no reference to the particular data or domain in
which they work.
These include many things you have heard (or maybe even used),
including principal components analysis, convolutional neural
networks, random forests, \todo{[t-SNE here]}, auto-encoders,
generative adversarial networks, support vector machines,
and Gaussian processes,
just to name a few\footnote{This short list (given
  that it includes generative adversarial networks but does not
  include whatever's next) will stand as a very precise time-stamp for
  when this \documentname\ was written.}
that have appeared in the astronomical literature.

So where is machine learning being used in astronomy and why?  Here is
an incomplete list, with just a few instances cited.\footnote{This
  list is not anything like a review of the literature; please don't
  treat it as such!}
\begin{description}
\item[classifcation]
...Classification problems that humans can solve but expert systems
can't. Galaxy Zoo post-process; RF variable stars.
\item[structured nuisances]
...Nuisances we don't care about, like galaxy SEDs; all we want is
photo-zs. Also the star--quasar and galaxy-star classification
problems. And The Cannon.
\item[visualization and discovery]
...Visualization and discovery in complex data sets, like t-SNE in RAVE
or k-means in APOGEE. Or RF in SDSS.
\item[operational monitoring]
...Operational situations: Are telescopes operating normally? I don't know
of cases here.
\item[speeding computation]
...Speeding computation; emulators.
\end{description}

\section{Who are you?}

...I am assuming that anyone reading this \documentname\ has a
significant fraction of the following properties:

...Make sure to cite Bishop as background reading.

...Warning: This \documentname\ will be extremely non-linear, because
the connections across different subjects are myriad. If you know what
you are doing, and all you are looking for is my polemical advice, you
want to skip to \todo{where?}. If you just want to skim the relevant
algorithm names to get some ideas for some application you have in
mind, you can just read (or skim) \todo{what?}. If you just want to arm
yourself with cynical, critical material for fending off machine-learning
proponents, you will want to concentrate on \todo{which?}.

\section{Basic taxonomy of machine-learning tasks}

There is a hierarchy of machine-learning tasks, with boundaries that
are a bit fuzzy.
At the top of this hierarchy is the dichotomy between \emph{supervised}
and \emph{unsupervised} methods.
In supervised methods, the idea is that there is a \emph{training set}
of data, for which there is some kind of data (in astronomy this would
be imaging or spectroscopy or light curves or something like those),
and there are also some kind of \emph{labels}.
These might be binary labels (star \vs\ quasar, for example) or
categorical labels (elliptical, spiral, lenticular, irregular, for
example) or continuous labels (temperature and surface gravity and
iron abundance, for example).
The machine-learning task is to learn---from the training set---the
relationship between the data and the labels, and then apply that
relationship to infer new labels for previously unlabeled data.

The primary supervised learning tasks are \emph{classification} (when
the labels are binary or categorical) and \emph{regression} (when the
labels are continuous.
As in many other mathematical contexts (optimization, root finding,
and so on), these tasks appear superficially similar, but the mathematical
techniques look very different, because cardinality.
We are going to talk about these tasks below, and even spell out for
each of them a very simple, very powerful algorithm.
Astronomers even with no machine-learning background are very used
to performing tasks that looke like or are regressions:
These are basically equivalent to fitting functional relationships to
observed data.

In the unsupervised methods, the idea is that there are no labels,
there are just the data themselves.
The machine-learning method or algorithm is asked to find
structure in the data and describe or reveal or capitalize on that
structure somehow.
For example, think about typical images: They might have millions
of pixels each and each pixel might have 24 bits of information in it.
In principle, therefore, images live in a space that has a cardinality
(in base 10) that requires tens of millions of decimal places!
And yet, if you generate artificial data by just randomly choosing
integers of that size and visualizing them as images, almost none of
the numbers you will ever generate will look even the slightest bit
like any real image that would be taken by a camera or a telescope.
That is, real images live in a tiny, tiny subspace of all possible
images.
That is, the subspace of real images is highly informative.
That's just an overly specific example, but the point is that
unsupervised methods are designed to find and describe these kinds of subspaces.

Unsupervised methods subdivide (again, only fuzzily) into various
kinds of tasks.
In \emph{clustering}, the goal is to categorize the data into categories
of similar objects.
In \emph{dimensionality reduction}, the goal is to project or
transform the (usually high dimensional) data into a lower dimensional
space that is smaller but somehow captures or preserves most or all or
the most important structure.
In \emph{density estimation}, the goal is to describe the distribution
of data within the data space in a volumetric or measure sense.

In some sense, clustering and dimensionality reduction are very closely
related, with one being categorical and the other continuous.
They both try to replace the high dimensional data with a smaller number of
pieces of information (discrete classes or continuous features).
These are related  in the
same sense that classification and regression are closely related.
Density estimation is generally far harder than either clustering
or dimensionality reduction, especially as the dimensionality of the
data get large, because it is hard to build models (or have training
data) that have support in a large fraction of even any relevant
subspace of any high dimensional space.

In the next five sections I am going to describe in some detail one
canonical algorithm or method for each of these five tasks
(classification, regression, dimensionality reduction, clustering,
and density estimation).
I will choose these five algorithms on the basis of their beauty, their
simplicity, their power, and their pedagogical value.
I will follow the canonical algorithm descriptions with discussions
of limitations, extensions, and far more powerful algorithms, along
with some barely justifiable advice.
These five sections are followed by sections that discuss statistical,
conceptual, scientific, and mathematical considerations that cut
across applications and algorithms.

\section{Classification}

...Supervised. In astro: Star--galaxy, high-redshift quasars, cosmic rays.

...SVM

...kSVM. Concept of non-parametrics, to be discussed below.

...Rando Forest

...NNs, CNNs, RNNs, GANs, etc

...What is classification to a bayesian, and how does this relate?

\section{Regression}

...Supervised; relationship to classification. In astro: The Cannon. Kepler and LIGO systematics.

...Linear regression!

...Rando Forest, CNNs, and all the stuff from last section.

...Gaussian Processes (and we will elaborate more later). Likelihood function appears!

\section{Dimensionality reduction}

...Unsupervised. In astro: spectral templates. Feature engineering.

...PCA!

...kPCA. Why don't astronomers use this? The Dual problem problem.

...PPCA, FA, and latent-variable models like GPLVM

...Manifold-learning and t-SNE. Relationships to visualization and feature engineering (more below).

...auto-encoders: Probably useful!

...GANs

\section{Clustering}

...Unsupervised. In astro: SNe types, spectral types.

...k-means!

...[Here I am weakest]

...Using classifiers or regressions to find outliers. (The opposite of clustering.)

\section{Density estimation}

...Unsupervised. In astro: Comparing populations. Pseudo-LFs and pseudo-posteriors. Other things?

...GMM with E-M algo!

...Relationship to clustering and various confusions around that.

...XD, and why we care. And how did this become a classification algorithm? Connections there.

...RNADE

...GANs: In what sense do these estimate density?

\section{Rectangular data}

...format

...but also issues with missing data (to return below)

...kinds of data that can't be made rectangular (trivially). Specifically mention variable-star light curves.

...importance of feature engineering if you must go rectangular.

...importance of distance metrics if you can't!

\section{Distance metrics}

...Most ML methods are nearest-neighbor methods, in some sense!

\section{Statistical principles}

...train, validate, and test.

...concepts of statistical conservatism

...stationarity requirements

\section{Probabilistic methods}

\section{Concept of non-parametrics}

\section{The kernel trick}

\section{Gaussian processes}

\section{Active learning}

\section{Feature engineering}

\section{Interpretability}

\section{Generalizability}

\section{Unsolicited advice}

...only GPs are fully probabilistic and non-parametric

...model nuisances

...model or locate outliers

...operational contexts

...emulators

\end{document}
